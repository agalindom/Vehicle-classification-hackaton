{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip input/images/images.zip -d input/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q efficientnet_pytorch > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import helpers\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from apex import amp\n",
    "import torch.nn as nn\n",
    "import pretrainedmodels\n",
    "import albumentations as A\n",
    "from sklearn import metrics\n",
    "from torch.nn import functional as F\n",
    "from models import SEResNext50_32x4d, SEResNeXt101_32x4d, NASnet\n",
    "from Dataset import VehicleTrainDataset, VehicleTrainDataset2\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = SEResNeXt101_32x4d(pretrained = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "    \n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "    net._fc = nn.Linear(in_features=2560, out_features=1, bias=True)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Albumentations\n",
    "def train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.CenterCrop(height=224, width=224, p=0.2),\n",
    "#             A.OneOf([\n",
    "#                 A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "#                                      val_shift_limit=0.2, p=0.9),\n",
    "#                 A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "#                                            contrast_limit=0.2, p=0.9),\n",
    "#             ],p=0.9),\n",
    "            A.ToGray(p=0.1),\n",
    "#             A.CLAHE(p=5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=5, p=0.9),\n",
    "            A.Flip(p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "#                                      val_shift_limit=0.2, p=0.5),\n",
    "#             A.GaussianBlur(p=0.1),\n",
    "#             A.GaussNoise(p=0.1),\n",
    "#             A.OpticalDistortion(p=0.5),\n",
    "            A.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225), max_pixel_value = 255., always_apply = True)\n",
    "#             ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def valid_transforms():\n",
    "    return A.Compose([\n",
    "        A.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225), max_pixel_value = 255., always_apply = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training functions\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "def train_effdet(\n",
    "    epoch,\n",
    "    train_loader,\n",
    "    model, \n",
    "    optimizer, \n",
    "    device,\n",
    "    trainset, \n",
    "    validset,\n",
    "    valid_loader,\n",
    "    scheduler = None,\n",
    "    iterations = 1,\n",
    "    fp16 = False\n",
    "):\n",
    "    criterion = LabelSmoothing().to(device)\n",
    "    \n",
    "    if fp16:\n",
    "        iterations = 1\n",
    "    losses = helpers.AverageMeter()\n",
    "    predictions = []\n",
    "    model.train()\n",
    "    if iterations > 1:\n",
    "        optimizer.zero_grad()\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch, data in enumerate(tk0):\n",
    "        for key, value in data.items():\n",
    "            data[key] = value.to(device)\n",
    "        if iterations == 1 and batch == 0:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        targets = data[\"targets\"].to(device).float()\n",
    "        images = data[\"image\"].to(device).float()\n",
    "        \n",
    "        out = model(images)\n",
    "        loss = nn.BCEWithLogitsLoss()(out, targets.view(-1,1))\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            if fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                \n",
    "            else: \n",
    "                loss.backward()\n",
    "            if (batch + 1) % iterations == 0:\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                if batch > 0:\n",
    "                    optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        losses.update(loss.detach().item(), train_loader.batch_size)\n",
    "        tk0.set_postfix(loss=losses.avg)\n",
    "    \n",
    "    \n",
    "    ### validation\n",
    "    val_losses = helpers.AverageMeter()\n",
    "    final_predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_acc = 0.\n",
    "        tk1 = tqdm(valid_loader, total=len(valid_loader))\n",
    "        for batch, data in enumerate(tk1):\n",
    "            for key , value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            targets = data[\"targets\"].to(device).float()\n",
    "            images = data[\"image\"].to(device).float()\n",
    "\n",
    "            out = model(images)\n",
    "            loss = nn.BCEWithLogitsLoss()(out, targets.view(-1,1))\n",
    "            predictions = out.cpu()\n",
    "            val_losses.update(loss.detach().item(), valid_loader.batch_size)\n",
    "#             predictions = nn.functional.softmax(predictions, dim=1).data.cpu().numpy()[:,1]\n",
    "            final_predictions.append(predictions.view(-1,1))\n",
    "            tk1.set_postfix(loss=val_losses.avg)\n",
    "    \n",
    "    return final_predictions, losses.avg, val_losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    epoch,\n",
    "    train_loader,\n",
    "    model, \n",
    "    optimizer, \n",
    "    device,\n",
    "    trainset, \n",
    "    validset,\n",
    "    valid_loader,\n",
    "    scheduler = None,\n",
    "    iterations = 1,\n",
    "    fp16 = False\n",
    "):    \n",
    "    if fp16:\n",
    "        iterations = 1\n",
    "    losses = helpers.AverageMeter()\n",
    "    predictions = []\n",
    "    model.train()\n",
    "    if iterations > 1:\n",
    "        optimizer.zero_grad()\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch, data in enumerate(tk0):\n",
    "        for key, value in data.items():\n",
    "            data[key] = value.to(device)\n",
    "        if iterations == 1 and batch == 0:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        out, loss = model(**data)\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            if fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                \n",
    "            else: \n",
    "                loss.backward()\n",
    "            if (batch + 1) % iterations == 0:\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                if batch > 0:\n",
    "                    optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        losses.update(loss.item(), train_loader.batch_size)\n",
    "        tk0.set_postfix(loss=losses.avg)\n",
    "    \n",
    "    \n",
    "    ### validation\n",
    "    val_losses = helpers.AverageMeter()\n",
    "    final_predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tk1 = tqdm(valid_loader, total=len(valid_loader))\n",
    "        for batch, data in enumerate(tk1):\n",
    "            for key , value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            out, val_loss = model(**data)\n",
    "            predictions = out.cpu()\n",
    "            val_losses.update(loss.detach().item(), valid_loader.batch_size)\n",
    "            final_predictions.append(predictions)\n",
    "#             total_acc += accuracy(out, data[\"targets\"].view(-1,1))\n",
    "            tk1.set_postfix(loss=val_losses.avg)\n",
    "    nv = len(valid_loader)\n",
    "    \n",
    "    return final_predictions, losses.avg, val_losses.avg#total_acc/nv).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fold = None):\n",
    "    print(f\"[FOLD]: {fold}\")\n",
    "    train_data = \"input/images/images\"\n",
    "    df = pd.read_csv(\"input/train_folds.csv\")\n",
    "    train_bs = 32\n",
    "    valid_bs = 16\n",
    "\n",
    "    # kfold validation\n",
    "    train_df = df[df.kfold != fold].reset_index(drop = True)\n",
    "    valid_df = df[df.kfold.isin([fold])].reset_index(drop = True)\n",
    "\n",
    "    trainset = VehicleTrainDataset(train_df, image_dir = train_data,\n",
    "                                         transforms = train_transforms())\n",
    "    validset = VehicleTrainDataset(valid_df, image_dir = train_data,\n",
    "                                         transforms = valid_transforms())\n",
    "    \n",
    "    #### effdet\n",
    "#     trainset = VehicleTrainDataset2(train_df, train_df.emergency_or_not.values, image_dir = train_data,\n",
    "#                                          transforms = train_transforms())\n",
    "#     validset = VehicleTrainDataset2(valid_df, valid_df.emergency_or_not.values, image_dir = train_data,\n",
    "#                                          transforms = valid_transforms())\n",
    "\n",
    "#     print(len(trainset))\n",
    "#     print(len(validset))\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        dataset = trainset,\n",
    "        batch_size=train_bs,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    validloader = DataLoader(\n",
    "        dataset = validset,\n",
    "        batch_size=valid_bs,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    device = \"cuda\"\n",
    "    epochs = 50\n",
    "    lr = 1e-4\n",
    "#     lr = 0.0005\n",
    "    \n",
    "#     model = NASnet(pretrained = \"imagenet+background\")\n",
    "    model = SEResNeXt101_32x4d(pretrained = 'imagenet')\n",
    "#     model = get_net().cuda()\n",
    "    model_path = f\"Output/{type(model).__name__}_{fold}.pth\"\n",
    "    model.to(device)\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(optimizer_parameters, lr = lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',\n",
    "        factor=0.8,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    \n",
    "#     amp.register_float_function(torch, 'sigmoid')\n",
    "    \n",
    "    model, optimizer = amp.initialize(\n",
    "        model, \n",
    "        optimizer,\n",
    "        opt_level=\"O1\",\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    es = helpers.EarlyStopping(patience = 5, mode=\"max\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        predictions, train_loss, valid_loss = train(\n",
    "            epoch,\n",
    "            trainloader,\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            trainset, \n",
    "            validset,\n",
    "            validloader,\n",
    "            iterations = 1,\n",
    "            fp16 = True)\n",
    "        \n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "#         targets = np.array(valid_df.emergency_or_not) >= 0.5\n",
    "        predictions = [0 if i < 0.5 else 1 for i in predictions]\n",
    "        acc = metrics.accuracy_score(valid_df.emergency_or_not, predictions)\n",
    "        \n",
    "#         acc = metrics.roc_auc_score(targets, predictions)\n",
    "        scheduler.step(acc)\n",
    "        \n",
    "        print(f\"Epoch: {epoch} train_loss:{round(train_loss,3)}, valid_loss: {round(valid_loss,3)} acc: {acc:.3f}\")\n",
    "        es(acc, model, model_path)\n",
    "        if es.early_stop:\n",
    "            print(\"Early Stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD]: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:28<00:00,  1.47it/s, loss=0.288]\n",
      "100%|██████████| 21/21 [00:03<00:00,  6.37it/s, loss=0.0363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train_loss:0.288, valid_loss: 0.036 acc: 0.924\n",
      "Validation score improved (-inf --> 0.9242424242424242). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.116]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.20it/s, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train_loss:0.116, valid_loss: 0.127 acc: 0.945\n",
      "Validation score improved (0.9242424242424242 --> 0.9454545454545454). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.88it/s, loss=0.0967]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.30it/s, loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train_loss:0.097, valid_loss: 0.163 acc: 0.961\n",
      "Validation score improved (0.9454545454545454 --> 0.9606060606060606). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0538]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.21it/s, loss=0.0719]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train_loss:0.054, valid_loss: 0.072 acc: 0.958\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0474]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.09it/s, loss=0.00181]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train_loss:0.047, valid_loss: 0.002 acc: 0.952\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0418]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.11it/s, loss=0.035]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train_loss:0.042, valid_loss: 0.035 acc: 0.961\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.03]  \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.25it/s, loss=0.00108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train_loss:0.03, valid_loss: 0.001 acc: 0.964\n",
      "Validation score improved (0.9606060606060606 --> 0.9636363636363636). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0203]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.30it/s, loss=0.000669]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train_loss:0.02, valid_loss: 0.001 acc: 0.964\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.88it/s, loss=0.0365] \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.18it/s, loss=0.94]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train_loss:0.036, valid_loss: 0.94 acc: 0.955\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.88it/s, loss=0.0137] \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.20it/s, loss=0.00214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train_loss:0.014, valid_loss: 0.002 acc: 0.967\n",
      "Validation score improved (0.9636363636363636 --> 0.9666666666666667). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0107] \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.14it/s, loss=0.000154]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train_loss:0.011, valid_loss: 0.0 acc: 0.964\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.1]    \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.21it/s, loss=3.76]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 train_loss:0.1, valid_loss: 3.759 acc: 0.961\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.88it/s, loss=0.0403]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.16it/s, loss=0.00173]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 train_loss:0.04, valid_loss: 0.002 acc: 0.955\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0151]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.16it/s, loss=0.0139]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 train_loss:0.015, valid_loss: 0.014 acc: 0.967\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.87it/s, loss=0.0422]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.23it/s, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 train_loss:0.042, valid_loss: 1.002 acc: 0.964\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping!\n",
      "[FOLD]: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:25<00:00,  1.64it/s, loss=0.275]\n",
      "100%|██████████| 21/21 [00:02<00:00,  7.83it/s, loss=0.209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train_loss:0.275, valid_loss: 0.209 acc: 0.930\n",
      "Validation score improved (-inf --> 0.9300911854103343). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.105]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.11it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train_loss:0.105, valid_loss: 0.013 acc: 0.954\n",
      "Validation score improved (0.9300911854103343 --> 0.9544072948328267). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.0723]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.08it/s, loss=0.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train_loss:0.072, valid_loss: 0.11 acc: 0.960\n",
      "Validation score improved (0.9544072948328267 --> 0.9604863221884499). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0535]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.07it/s, loss=0.0351]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train_loss:0.054, valid_loss: 0.035 acc: 0.954\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.045] \n",
      "100%|██████████| 21/21 [00:01<00:00, 11.08it/s, loss=0.00223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train_loss:0.045, valid_loss: 0.002 acc: 0.964\n",
      "Validation score improved (0.9604863221884499 --> 0.9635258358662614). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0546]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.08it/s, loss=0.00281]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train_loss:0.055, valid_loss: 0.003 acc: 0.960\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0434]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.10it/s, loss=0.00772]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train_loss:0.043, valid_loss: 0.008 acc: 0.957\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0296]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.13it/s, loss=0.0355]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train_loss:0.03, valid_loss: 0.036 acc: 0.957\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0225]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.13it/s, loss=0.0223]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train_loss:0.023, valid_loss: 0.022 acc: 0.960\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.85it/s, loss=0.0283]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.09it/s, loss=0.00224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train_loss:0.028, valid_loss: 0.002 acc: 0.957\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping!\n",
      "[FOLD]: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.293]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.12it/s, loss=0.578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train_loss:0.293, valid_loss: 0.578 acc: 0.933\n",
      "Validation score improved (-inf --> 0.9331306990881459). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.83it/s, loss=0.117]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.04it/s, loss=0.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train_loss:0.117, valid_loss: 0.087 acc: 0.948\n",
      "Validation score improved (0.9331306990881459 --> 0.9483282674772037). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.83it/s, loss=0.081] \n",
      "100%|██████████| 21/21 [00:01<00:00, 10.96it/s, loss=0.0207]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train_loss:0.081, valid_loss: 0.021 acc: 0.948\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.0494]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.13it/s, loss=0.00644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train_loss:0.049, valid_loss: 0.006 acc: 0.954\n",
      "Validation score improved (0.9483282674772037 --> 0.9544072948328267). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.0411]\n",
      "100%|██████████| 21/21 [00:01<00:00, 10.99it/s, loss=0.222]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train_loss:0.041, valid_loss: 0.222 acc: 0.948\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.83it/s, loss=0.0475]\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.01it/s, loss=0.538]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train_loss:0.048, valid_loss: 0.538 acc: 0.945\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:22<00:00,  1.84it/s, loss=0.0641]\n",
      "100%|██████████| 21/21 [00:01<00:00, 10.95it/s, loss=0.357]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train_loss:0.064, valid_loss: 0.357 acc: 0.948\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    }
   ],
   "source": [
    "main(0)\n",
    "main(1)\n",
    "main(2)\n",
    "# main(3)\n",
    "# main(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
